{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (Big part about learning DL is quite intuitive!) Notes taken from Lesson 1, 2 fastbook\n",
    "## Deep Learning: Neural Network\n",
    "Isn’t it fascinating that we are trying to understand what our brains are doing in order to figure out how to effectively build a learning model. As explained in Parallel Distributed Processing (PDP) by David Rumelhart, “people are smarter than today’s computers because the brain employs a basic computational architecture that is more suited to deal with a central aspect of the natural information processing tasks that people are so good at.” ‘This natural computational framework in our brain is essentially what we also want to deploy in our machines. \n",
    "\n",
    "Arthur Samuel (former IBM researcher) shares a similar sentiment. In his classic 1962 essay “Artificial Intelligence: a Frontier of Automation,” he wrote “programming a computer for such computations is, at best, a difficult task, not primarily because of any inherent complexity in the computer itself but rather, because of the need to spell out every minute step of the process in the snot exasperating detail. Computers, as any programmer will tell you, are giant morons, not giant brains.” His reasoning is simple: instead of writing out every single exasperatingly detailed instructions for your machine, teaching the machine to learn (deploy) a model to solve problems is more efficient in the long run. \n",
    "\n",
    "Deep learning is deep because we don’t exactly know how to compute a universal labeling system for all cats and dogs. Unlike linear regression where we can see each weight (beta-coefficients) linked to each factor, deep neural network has multiple hidden layers where they optimize its parameters to best perform the task given \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limitations of DL models\n",
    "- A model cannot be create without data, which means a model can only learn to operate on the patterns seen in the input data used to train it \n",
    "    - e.g) Recommendation system based on user behavior is likely to provide you with a list of items that the user already has or already knows about (because it is based on their purchase history). Recommendation might be accurate (because it matches user history) but may not be helpful (because the user might want to know something new) — how do we incorporate this 'new-ness' in to machines? If it is only trained by machines? It recommends what a user might like but not what would be helpful to users "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- More bias in data translates to bias in model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This learning approach only creates predictions and not recommended actions\n",
    "    - Remember from IB, TOK we talked about whether people are natural pattern seekers? Finding patterns might be a good way of learning about things, but it also has its limitations \n",
    "    - What about emotional learning - i guess this is more related to retaining knowledge (from the article \"we learn only to forget\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics\n",
    "- error rate/ accuracy rate: measures the quality of model’s prediction \n",
    "- Loss: measure the performance (so that the training system can use to update weights automatically) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning Terminologies\n",
    "- Label - catagorization results \n",
    "- Architecture - template of the model (the actual mathematical functions vlbs)\n",
    "- Model - architecture + parameters\n",
    "- Fit (or train) - update parameters so that the predictions of the model using the input data matches the target labels\n",
    "- Pretrained model: model that is already trained using a larger dataset (and will be fine-tuned)\n",
    "- Fine-tune - update a pretrained model for a different task \n",
    "- Epoch - one complete pass through the input data\n",
    "- Loss - measure of model performance\n",
    "- Metric - measure of model accuracy\n",
    "- Validation set/ training set/ \n",
    "- CNN: convolutional neural network (a type of neural network that works particularly well for computer vision tasks) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Set\n",
    "- goal: validation and test sets must be representative of the new data you will see in the future. Test set is for final evaluation. Validation set is a part of human conditioning hyperparameters process and thus a part of the ‘training’ model process and so it will inevitably increase the risk of overfitting. Overfitting happens because of a limited set of data and it does not generalize well to unseen data \n",
    "\n",
    "### GPU\n",
    "- graphics processing unit is specialized for displaying graphics. The hardware optimization used in GPUs allow it to handle thousands of tasks at the same time. /incidentally, these optimizations allow us to run and train neural networks hundreds of times faster than a regular CPU\n",
    "\n",
    "### Process of building and training model\n",
    "- 1) architecture (mathematical functions) of your problem\n",
    "- 2) collect and clean data to train ur model. Remember to have validation, test, and training set. Test set is something u have and will never touch. Validation set is to check how it’s doing. Training set builds the model. Label data correctly.\n",
    "- 3) define loss function to quantitatively measure the performance and we need a way to update these parameters in order to improve its performance\n",
    "\n",
    "### DL benefits: Good at handling high-cardinality categorical variables\n",
    "- Combining variables with other kinds of data \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
